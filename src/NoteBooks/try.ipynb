{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(\"..\", \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.enums.PathEnums import Paths\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image_path, label):\n",
    "    \n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    img_as_array = np.array(img)\n",
    "\n",
    "    print(f\"Image path: {image_path}\")\n",
    "    print(f\"Image class: {label}\")\n",
    "    print(f\"Image shape: {img_as_array.shape}\")\n",
    "    plt.imshow(img_as_array)\n",
    "    plt.title(f\"Random Image from '{label}' class\")\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as F\n",
    "\n",
    "def plot_images(data, labels, transformed=False):\n",
    "\n",
    "    n = len(data)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(n * 5, 5))  \n",
    "\n",
    "    if n == 1:\n",
    "        axes = [axes]  # If only 1 image, make sure axes is iterable\n",
    "\n",
    "    if transformed:\n",
    "\n",
    "\n",
    "\n",
    "        for i, (img, label) in enumerate(zip(data, labels)):\n",
    "            # img is a tensor in [C, H, W]\n",
    "            # img = F.to_pil_image(img)  # convert back to PIL\n",
    "            img = img.permute(1, 2, 0)\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f\"Image {label}\")\n",
    "            axes[i].axis(\"off\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        for i, image_path in enumerate(data):\n",
    "            img = Image.open(image_path)\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f\"Image {labels[i]}\")\n",
    "            axes[i].axis(\"off\")\n",
    "\n",
    "    # plt.suptitle(f\"Random Images from '{category}' class\", fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetSplitter:\n",
    "\n",
    "    def __init__(self):\n",
    "        print(\"DatasetSplitter initialize...\")\n",
    "\n",
    "    def get_all_annotations(self):\n",
    "\n",
    "        with open(os.path.join('../../', Paths.ANNOT_PKL.value), \"rb\") as f:\n",
    "            videos_annot_dct = pickle.load(f)\n",
    "\n",
    "        labels = set()\n",
    "        all_annotations = []\n",
    "        train_split = []\n",
    "        valid_split = []\n",
    "        test_split = []\n",
    "        i_tr, i_v, i_ts, i_all = 0, 0, 0, 0\n",
    "\n",
    "        train_ids = [\"1\", \"3\", \"6\", \"7\", \"10\", \"13\", \"15\", \"16\", \"18\", \"22\", \"23\", \"31\",\n",
    "                    \"32\", \"36\", \"38\", \"39\", \"40\", \"41\", \"42\", \"48\", \"50\", \"52\", \"53\", \"54\"]\n",
    "\n",
    "\n",
    "        val_ids = [\"0\", \"2\", \"8\", \"12\", \"17\", \"19\", \"24\", \"26\", \"27\", \"28\", \"30\", \"33\", \"46\", \"49\", \"51\"]\n",
    "\n",
    "        for video_id, clips in videos_annot_dct.items(): # each video\n",
    "\n",
    "            for clip_id, clip_data in clips.items():     # each clip\n",
    "\n",
    "                category = clip_data['category']\n",
    "                labels.add(category)\n",
    "\n",
    "                for frame_id, boxes in clip_data[\"frame_boxes_dct\"].items():    # Frames\n",
    "\n",
    "                    # if str(frame_id) == str(clip_id) :\n",
    "                        # print(f\"===: {video_id} || {clip_id} || {frame_id}, {category}\")\n",
    "                    frame_path = f\"{Paths.VIDEOS_ROOT.value}/{video_id}/{clip_id}/{frame_id}.jpg\"\n",
    "                    i_all+=1\n",
    "                    all_annotations.append(\n",
    "                        {\n",
    "                            \"path\": os.path.join('../../', frame_path), \n",
    "                            \"category\": category\n",
    "                        }\n",
    "                    )\n",
    "                    if str(video_id) in train_ids:\n",
    "                        i_tr+=1\n",
    "                        # if i_tr == 2:\n",
    "                        #     print(f\"{i_tr}_train: path: {frame_path}, category: {category}\")\n",
    "                            # plot_image(frame_path, category)\n",
    "                        train_split.append({\"path\": os.path.join('../../', frame_path),   \"category\": category })\n",
    "                    elif str(video_id) in val_ids:\n",
    "                        i_v+=1\n",
    "                        # if i_v == 3:\n",
    "                        #     print(f\"{i_v}_valid: path: {frame_path}, category: {category}\")\n",
    "                            # plot_image(frame_path, category)\n",
    "                        valid_split.append({\"path\": os.path.join('../../', frame_path),   \"category\": category })\n",
    "                    else:\n",
    "                        i_ts+=1\n",
    "                        # if i_ts == 1:\n",
    "                        #     print(f\"{i_ts}_test: path: {frame_path}, category: {category}\")\n",
    "                        #     plot_image(frame_path, category)\n",
    "                        test_split.append({\"path\": os.path.join('../../', frame_path),   \"category\": category })\n",
    "\n",
    "        print(i_tr, i_v, i_ts, i_tr+i_v+i_ts, i_all)\n",
    "\n",
    "\n",
    "        random.shuffle(train_split)\n",
    "        random.shuffle(valid_split)\n",
    "        random.shuffle(test_split)\n",
    "        random.shuffle(all_annotations)\n",
    "\n",
    "        return all_annotations, train_split, valid_split, test_split, sorted(list(labels))\n",
    "# ===================================\n",
    "def split_data():\n",
    "    print(\"Start DatasetSplitter...\\n\")\n",
    "\n",
    "    splitter = DatasetSplitter()\n",
    "    all_data, train_split, valid_split, test_split, labels = splitter.get_all_annotations()\n",
    "    \n",
    "    print(\"labels: \", labels, \"\\n\")\n",
    "    print(f\"len data: {len(all_data)} || train: {len(train_split)} || valid: {len(valid_split)} || test: {len(test_split)}\")\n",
    "    print(\"===\"*50, \"\\n\")\n",
    "\n",
    "    return train_split, valid_split, test_split, labels\n",
    "# ==============================================\n",
    "train_split, valid_split, test_split, labels = split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len data: 43470 || train: 19368 || valid: 12069 || test: 12033\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transformed_images(image_paths_list, transform, seed=42):\n",
    "    # random.seed(seed)\n",
    "    set_seed(123)\n",
    "\n",
    "\n",
    "    for image_path in image_paths_list:\n",
    "        with Image.open(image_path) as f:\n",
    "            # img_as_array = np.asarray(f)\n",
    "            # print(f\"Image shape: {img_as_array.shape}\")\n",
    "            fig, ax = plt.subplots(1, 2)\n",
    "            ax[0].imshow(f) \n",
    "            ax[0].set_title(f\"Original \\nSize: {np.asarray(f).shape}\")\n",
    "            ax[0].axis(\"off\")\n",
    "\n",
    "            # Transform and plot image\n",
    "            # Note: permute() will change shape of image to suit matplotlib \n",
    "            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])\n",
    "            transformed_image = transform(f).permute(1, 2, 0) \n",
    "            ax[1].imshow(transformed_image)\n",
    "            ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
    "            ax[1].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_path_train1, lst_label_train1 = [], []\n",
    "\n",
    "i=0\n",
    "for d in train_split:\n",
    "    lst_path_train1.append(d['path'])\n",
    "    lst_label_train1.append(d['category'])\n",
    "    print(d)\n",
    "    i+=1\n",
    "    if i==3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transform = transforms.Compose([\n",
    "#         transforms.Resize((256, 256)),\n",
    "#         transforms.CenterCrop((224, 224)),\n",
    "#         # transforms.Resize((224, 224)),\n",
    "#         transforms.RandomRotation(15),\n",
    "#         transforms.RandomApply([\n",
    "#             transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1)\n",
    "#         ], p=0.3),\n",
    "#         transforms.RandomGrayscale(p=0.05),\n",
    "#         transforms.RandomApply([\n",
    "#         transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0))\n",
    "#         ], p=0.3),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                             std=[0.229, 0.224, 0.225])\n",
    "#     ])\n",
    "\n",
    "set_seed(123)\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop((224, 224)),\n",
    "        # transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.1),\n",
    "        transforms.RandomVerticalFlip(p=0.1),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(brightness=0.02, contrast=0.02, saturation=0.02)\n",
    "        ], p=0.06),\n",
    "        transforms.RandomGrayscale(p=0.05),\n",
    "        transforms.RandomApply([\n",
    "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 0.5))\n",
    "        ], p=0.06),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(lst_path_train1[0])\n",
    "img_as_array = np.array(img)\n",
    "print(f\"Before Transform : {img_as_array.shape}\") \n",
    "transformed_img = data_transform(img)\n",
    "print(f\"After Transform : {transformed_img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transformed_images(lst_path_train1, \n",
    "                        transform=data_transform, \n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_split, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_split: list of dicts [{\"path\": ..., \"category\": ...}, ...]\n",
    "            labels: full list of class labels\n",
    "            transform: torchvision transforms\n",
    "        \"\"\"\n",
    "        set_seed(123)\n",
    "        \n",
    "        self.data_split = data_split\n",
    "        self.labels = labels\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(labels)}\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.data_split)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        item = self.data_split[idx]\n",
    "        img = Image.open(item[\"path\"]).convert(\"RGB\")\n",
    "        label = self.class_to_idx[item[\"category\"]]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # return item[\"path\"], img, label  # item[\"path\"] Remove this (Fawzy...)\n",
    "        return img, label\n",
    "\n",
    "# ==============================================================================\n",
    "\n",
    "def custom_data(train_split, valid_split, test_split, labels):\n",
    "    print(\"Start CustomDataset...\\n\")\n",
    "    set_seed(123)\n",
    "\n",
    "   \n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop((224, 224)),\n",
    "        # transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.1),\n",
    "        transforms.RandomVerticalFlip(p=0.1),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(brightness=0.02, contrast=0.02, saturation=0.02)\n",
    "        ], p=0.06),\n",
    "        transforms.RandomGrayscale(p=0.05),\n",
    "        transforms.RandomApply([\n",
    "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 0.5))\n",
    "        ], p=0.06),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "    test_transforms = transforms.Compose([\n",
    "            transforms.Resize((128, 125)),\n",
    "            transforms.CenterCrop((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225]\n",
    "                )\n",
    "        ])\n",
    "\n",
    "    train_dataset = CustomDataset(train_split, labels, transform=train_transforms)\n",
    "    valid_dataset = CustomDataset(valid_split, labels, transform=test_transforms)\n",
    "    test_dataset  = CustomDataset(test_split,  labels, transform=test_transforms)\n",
    "\n",
    "    print(f\"len train : {len(train_dataset)}\")\n",
    "    print(f\"len valid : {len(valid_dataset)}\")\n",
    "    print(f\"len test : {len(test_dataset)}\")  \n",
    "\n",
    "    print(valid_dataset.labels)\n",
    "    print(valid_dataset.class_to_idx)\n",
    "    print(\"=\"*50, \"\\n\")\n",
    "    return train_dataset, valid_dataset, test_dataset\n",
    "# =======================================================================\n",
    "train_split, valid_split, test_split, labels = split_data()\n",
    "print(\"\\n==================================================================================\\n\")\n",
    "train_dataset, valid_dataset, test_dataset = custom_data(train_split, valid_split, test_split, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_image, _ = train_dataset[0]\n",
    "val_image, _ = valid_dataset[0]\n",
    "tst_image, _ = test_dataset[0]\n",
    "\n",
    "tr_image.shape, val_image.shape, tst_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_idx = train_dataset.class_to_idx\n",
    "labels = train_dataset.labels\n",
    "class_idx, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_path_train1, lst_path_train2 = [], []\n",
    "lst_label_train1, lst_label_train2 = [], []\n",
    "\n",
    "i=0\n",
    "for d in train_split:\n",
    "    lst_path_train1.append(d['path'])\n",
    "    lst_label_train1.append(d['category'])\n",
    "    print(d)\n",
    "    i+=1\n",
    "    if i==3:\n",
    "        break\n",
    "print(\"**********************================================***************************\")\n",
    "for i, (img, label) in enumerate(train_dataset):\n",
    "    lst_path_train2.append(img)\n",
    "    lst_label_train2.append(labels[label])\n",
    "    # print(path, labels[label])\n",
    "    print(labels[label])\n",
    "    if i ==2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(lst_path_train1, lst_label_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(lst_path_train2, lst_label_train2, transformed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_path_tst1, lst_path_tst2 = [], []\n",
    "lst_label_tst1, lst_label_tst2 = [], []\n",
    "\n",
    "i=0\n",
    "for d in test_split:\n",
    "    lst_path_tst1.append(d['path'])\n",
    "    lst_label_tst1.append(d['category'])\n",
    "    print(d)\n",
    "    i+=1\n",
    "    if i==3:\n",
    "        break\n",
    "print(\"**********************================================***************************\")\n",
    "# for i, (path, img, label) in enumerate(test_dataset):\n",
    "for i, (img, label) in enumerate(test_dataset):\n",
    "\n",
    "    # lst_path_tst2.append(path)\n",
    "    lst_path_tst2.append(img)\n",
    "    lst_label_tst2.append(labels[label])\n",
    "    # print(path, labels[label])\n",
    "    print(labels[label])\n",
    "    if i ==2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(lst_path_tst1, lst_label_tst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(lst_path_tst2, lst_label_tst2, transformed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_image = lst_path_tst2[0].permute(1, 2, 0) \n",
    "plt.imshow(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_path_val1, lst_path_val2 = [], []\n",
    "lst_label_val1, lst_label_val2 = [], []\n",
    "\n",
    "i=0\n",
    "for d in valid_split:\n",
    "    lst_path_val1.append(d['path'])\n",
    "    lst_label_val1.append(d['category'])\n",
    "    print(d)\n",
    "    i+=1\n",
    "    if i==3:\n",
    "        break\n",
    "print(\"**********************================================***************************\")\n",
    "# for i, (img, label) in enumerate(valid_dataset):\n",
    "for i, (img, label) in enumerate(valid_dataset):\n",
    "\n",
    "    # lst_path_val2.append(path)\n",
    "    lst_path_val2.append(img)\n",
    "    lst_label_val2.append(labels[label])\n",
    "    # print(path, labels[label])\n",
    "    print(labels[label])\n",
    "    if i ==2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(lst_path_val1, lst_label_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(lst_path_val2, lst_label_val2, transformed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_path_train1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_dataset[0]\n",
    "class_names = train_dataset.labels\n",
    "class_to_idx = train_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.shape)\n",
    "print(label)\n",
    "print(class_names[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_random_images(dataset,\n",
    "                          classes,  #: List[str] = None,\n",
    "                          n: int = 10,\n",
    "                          display_shape: bool = True,\n",
    "                          seed: int = 42):\n",
    "    \n",
    "    if n > 10:\n",
    "        n = 10\n",
    "        display_shape = False\n",
    "        print(f\"For display purposes, n shouldn't be larger than 10, setting to 10 and removing shape display.\")\n",
    "    \n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "\n",
    "    random_samples_idx = random.sample(range(len(dataset)), k=n)\n",
    "    print(random_samples_idx)\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    for i, targ_sample in enumerate(random_samples_idx):\n",
    "        path, targ_image, targ_label = dataset[targ_sample][0], dataset[targ_sample][1], dataset[targ_sample][2]\n",
    "\n",
    "        targ_image_adjust = targ_image.permute(1, 2, 0)\n",
    "\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.imshow(targ_image_adjust)\n",
    "        plt.axis(\"off\")\n",
    "        if classes:\n",
    "            title = f\"class: {classes[targ_label]}\"\n",
    "            if display_shape:\n",
    "                title = title + f\"\\nshape: {targ_image_adjust.shape}\"\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_random_images(train_dataset, \n",
    "                      n=3, \n",
    "                      classes=class_names,\n",
    "                      seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_random_images(valid_dataset, \n",
    "                      n=3, \n",
    "                      classes=class_names,\n",
    "                      seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_random_images(test_dataset,\n",
    "                      n=3, \n",
    "                      classes=class_names,\n",
    "                      seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "test_dataloader  = DataLoader(test_dataset,  batch_size=128, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 32\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\")\n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {train_dataloader.batch_size}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {test_dataloader.batch_size}\")\n",
    "print(f\"Length of valid dataloader: {len(valid_dataloader)} batches of {valid_dataloader.batch_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataloader.batch_size)\n",
    "print(test_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=0\n",
    "for i in train_dataloader:  # i(list of tensors) ==> [Batch([32, 1, 28, 28]), labels([32])]\n",
    "    print(\"Batch\",l+1)\n",
    "    # print(type(i)) # List\n",
    "    print(\"size of i:\", len(i))              # Size = 2 List \n",
    "    print(\"shape of batch data: i[0] :\", i[0].shape,\"labels:i[1] :\", i[1].shape) # Tensor, Tensor\n",
    "    print(\"shape of first image in batch\", i[0][0].shape)\n",
    "    l+=1\n",
    "    if (l==2):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=========================\")\n",
    "for batch, i in enumerate (train_dataloader):  # c (Counter), i ==> [Batch([32, 1, 28, 28]), labels([32])]\n",
    "    print(\"Batch\", batch, \"===> \", i[0].shape, i[1].shape)\n",
    "    if batch == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch, (images, labels) in enumerate(train_dataloader):\n",
    "    print(f\"Batch {batch + 1}:\")  \n",
    "    print(f\"  Batch Images shape: {images.shape}\")   # [32, 1, 28, 28]\n",
    "    print(f\"  Batch Labels shape: {labels.shape}\")   # [32]\n",
    "    \n",
    "    print(f\"  Single Images: {images[0].shape}\")\n",
    "    print(f\"  Single Label: {labels[0].item()}\")\n",
    "    print(f\"  Label: {class_names[labels[0].item()]}\")\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from torchinfo  import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(resnet50, input_size=(32, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total, trainable\n",
    "\n",
    "total, trainable = count_params(resnet50)\n",
    "print(f\"\\nTotal parameters: {total:,}\")\n",
    "print(f\"Trainable parameters: {trainable:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_param_cpy = list(resnet50.parameters())\n",
    "\n",
    "for param in resnet50_param_cpy:\n",
    "    print(param.shape)\n",
    "    print(\"Before:\", param.requires_grad)\n",
    "    param.requires_grad = False\n",
    "    print(\"After :\", param.requires_grad)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "class_names, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = resnet50.fc.in_features\n",
    "print(\"===================================\")\n",
    "resnet50.fc = nn.Linear(in_features, num_classes)\n",
    "print(f\" Final layer replaced: {in_features} → {num_classes}\")\n",
    "print(resnet50.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tst = train_features_batch[0].unsqueeze(0)\n",
    "image_tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_input = torch.randn(1, 3, 224, 224)\n",
    "out = resnet50(image_tst)\n",
    "print(\"\\nForward pass output shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# Load pretrained ResNet50\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "print(\"  Loaded pretrained ResNet50 (ImageNet weights)\")\n",
    "\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "print(\"   Backbone frozen (only final FC will train)\")\n",
    "\n",
    "# Replace final layer\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, num_classes)\n",
    "print(f\"   Final layer replaced: {in_features} → {num_classes}\")\n",
    "\n",
    "# Training components\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "acctorch = Accuracy(task=\"multiclass\", num_classes=len(class_names))\n",
    "from timeit import default_timer as timer\n",
    "acctorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train() # put model in train mode\n",
    "train_loss, train_acc = 0.0, 0.0\n",
    "\n",
    "\n",
    "for batch, (X, y) in enumerate(train_dataloader):\n",
    "    # Send data to GPU\n",
    "    X, y = X.to(device), y.to(device)\n",
    "\n",
    "    print(f\"X shape: {X.shape}, label shape: {y.shape}\")\n",
    "\n",
    "    # Forward\n",
    "    y_pred = model(X)\n",
    "    loss = criterion(y_pred, y)\n",
    "\n",
    "        # Backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Metrics\n",
    "    train_loss += loss.item()\n",
    "    print(\"ACC Torch\", acctorch(y_pred.argmax(dim=1), y))\n",
    "    train_acc = acctorch(y_pred.argmax(dim=1), y)\n",
    "\n",
    "    print(f\"trai loss : {train_loss}\")\n",
    "    print(f\"train acc : {train_acc}\")\n",
    "    print(f\"Batch: =================> {batch}\")\n",
    "     break\n",
    "\n",
    "# Calculate loss and accuracy per epoch and print out what's happening\n",
    "avg_loss  = train_loss / len(train_dataloader)\n",
    "avg_acc = acctorch.compute()\n",
    "avg_acc = avg_acc.item()\n",
    "print(\"ggg\", avg_acc, avg_acc*100)\n",
    "acctorch.reset()\n",
    "print(f\"Train loss: {avg_loss:.5f} | Train accuracy: {avg_acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(data_loader: torch.utils.data.DataLoader,\n",
    "              model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "\n",
    "    \n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.to(device)\n",
    "    model.eval() \n",
    "    with torch.inference_mode(): \n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            test_pred = model(X)   \n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y,\n",
    "                y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels\n",
    "            )\n",
    "        \n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")\n",
    "def eval_model(model: torch.nn.Module, \n",
    "               data_loader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, \n",
    "                                y_pred=y_pred.argmax(dim=1)) # For accuracy, need the prediction labels (logits -> pred_prob -> pred_labels)\n",
    "        \n",
    "        # average loss/acc per batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "        \n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer \n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_count = []\n",
    "loss_values = []\n",
    "test_loss_values = []\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "torch.manual_seed(43)\n",
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "epochs = 1\n",
    "for epoch in range(1, epochs+1):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    train_step(data_loader=train_dataloader, \n",
    "        model=model, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn\n",
    "    )\n",
    "    test_step(data_loader=test_dataloader,\n",
    "        model=model_1,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn\n",
    "    )\n",
    "    train_time_end_on_gpu = timer()\n",
    "    total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,\n",
    "                                                end=train_time_end_on_gpu,\n",
    "                                                device=device)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from torchmetrics.classification import Accuracy\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_acc, avg_acc*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50Finetuner(nn.Module):\n",
    "    def __init__(self, num_classes: int, freeze_backbone: bool = True, lr: float = 1e-3):\n",
    "        \"\"\"\n",
    "        Fine-tuned ResNet50 model.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): number of classes in your dataset.\n",
    "            freeze_backbone (bool): if True, freeze feature extractor and only train FC head.\n",
    "            lr (float): learning rate for optimizer.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        # Load pretrained ResNet50\n",
    "        self.model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        print(\"  Loaded pretrained ResNet50 (ImageNet weights)\")\n",
    "\n",
    "        # Freeze backbone if required\n",
    "        if freeze_backbone:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "            print(\"   Backbone frozen (only final FC will train)\")\n",
    "        else:\n",
    "            print(\"   All layers are trainable\")\n",
    "\n",
    "        # Replace final layer\n",
    "        in_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(in_features, num_classes)\n",
    "        # for p in self.model.fc.parameters():\n",
    "        #     p.requires_grad = True\n",
    "        print(f\"   Final layer replaced: {in_features} → {num_classes}\")\n",
    "\n",
    "        # Training components\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.acctorch = Accuracy(task=\"multiclass\", num_classes=num_classes).to(self.device)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "        # self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def explore(self, input_size=(1, 3, 224, 224)):\n",
    "        \"\"\"\n",
    "        Print model summary and param counts.\n",
    "        \"\"\"\n",
    "        print(\"\\n--- Model Summary ---\\n\")\n",
    "        summary(self.model, input_size=input_size)\n",
    "\n",
    "        total = sum(p.numel() for p in self.model.parameters())\n",
    "        trainable = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "        print(f\"\\n   Total parameters: {total:,}\")\n",
    "        print(f\"     Trainable parameters: {trainable:,}\")\n",
    "\n",
    "    def print_train_time(self, start: float, end: float):\n",
    "        total_time = end - start\n",
    "        print(f\"Train time on {self.device}: {total_time:.3f} seconds\")\n",
    "        return total_time\n",
    "\n",
    "    def train_step(self,\n",
    "               data_loader: torch.utils.data.DataLoader\n",
    "                ):\n",
    "        \n",
    "        self.model.train() # put model in train mode\n",
    "        train_loss = 0.0\n",
    "\n",
    "\n",
    "        for batch, (X, y) in enumerate(data_loader):\n",
    "            # Send data to GPU\n",
    "            X, y = X.to(self.device), y.to(self.device)\n",
    "\n",
    "            # Forward\n",
    "            y_pred = self.model(X)\n",
    "            loss = self.criterion(y_pred, y)\n",
    "\n",
    "             # Backward\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # Metrics\n",
    "            train_loss += loss.item()\n",
    "            self.acctorch(y_pred.argmax(dim=1), y)\n",
    "    \n",
    "        # Calculate loss and accuracy per epoch and print out what's happening\n",
    "        avg_loss  = train_loss / len(data_loader)\n",
    "        avg_acc = self.acctorch.compute()\n",
    "        avg_acc = avg_acc.item()\n",
    "        self.acctorch.reset()\n",
    "        print(f\"Train loss: {avg_loss:.5f} | Train accuracy: {avg_acc*100}\")\n",
    "\n",
    "        return avg_loss, avg_acc\n",
    "\n",
    "\n",
    "    def test_step(self,\n",
    "                data_loader: torch.utils.data.DataLoader\n",
    "                ):\n",
    "        \n",
    "        self.model.eval() \n",
    "        test_loss = 0\n",
    "        \n",
    "        with torch.inference_mode(): \n",
    "            for X, y in data_loader:\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                \n",
    "                test_pred = self.model(X)\n",
    "                loss = self.criterion(test_pred, y)\n",
    "\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                self.acctorch(test_pred.argmax(dim=1), y)\n",
    "            \n",
    "            avg_loss  = test_loss / len(data_loader)\n",
    "            avg_acc = self.acctorch.compute()\n",
    "            avg_acc = avg_acc.item()\n",
    "            self.acctorch.reset()\n",
    "            print(f\"Test loss: {avg_loss:.5f} | Test accuracy: {avg_acc}%\\n\")\n",
    "            return avg_loss, avg_acc\n",
    "\n",
    "    def train_model(self, train_dataloader, valid_dataloader, epochs=5):\n",
    "        \"\"\"\n",
    "        Train the model with optional validation.\n",
    "\n",
    "        Args:\n",
    "            train_loader: DataLoader for training data\n",
    "            valid_loader: DataLoader for validation data\n",
    "            epochs (int): number of training epochs\n",
    "        \"\"\"\n",
    "        history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "        \n",
    "    \n",
    "        start_time = timer()\n",
    "        best_val_acc = 0\n",
    "\n",
    "        for epoch in range(1, epochs+1):\n",
    "\n",
    "            print(f\"Epoch: {epoch}/{epochs}\\n---------\")\n",
    "            train_loss, train_acc = self.train_step(train_dataloader)\n",
    "            val_loss, val_acc = self.test_step(valid_dataloader)\n",
    "\n",
    "\n",
    "            print(f\"Train loss: {train_loss:.4f} | Train acc: {train_acc*100:.2f}%\")\n",
    "            print(f\"Val   loss: {val_loss:.4f} | Val   acc: {val_acc*100:.2f}%\")\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                self.save_model(\"best_resnet50.pth\")\n",
    "\n",
    "            history[\"train_loss\"].append(train_loss)\n",
    "            history[\"train_acc\"].append(train_acc)\n",
    "            history[\"val_loss\"].append(val_loss)\n",
    "            history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        end_time = timer()\n",
    "        total_train_time_model_1 = self.print_train_time(start=start_time,\n",
    "                                                        end=end_time\n",
    "                                                        )\n",
    "        return history\n",
    "\n",
    "    def predict(self, x: torch.Tensor):\n",
    "        \"\"\"Predict class for a single input tensor\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.inference_mode():\n",
    "            x = x.unsqueeze(0).to(self.device)\n",
    "            y_pred = self.model(x)\n",
    "            return int(y_pred.argmax(dim=1).item())\n",
    "\n",
    "    def save_model(self, path=\"resnet50.pth\"):\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "        print(f\"Model saved to {path}\")\n",
    "    def load_model(self, path=\"resnet50.pth\"):\n",
    "        self.model.load_state_dict(torch.load(path, map_location=self.device))\n",
    "        self.model.to(self.device)\n",
    "        print(f\"Model loaded from {path}\")\n",
    "    def plot_history(self, history: dict):\n",
    "        plt.figure(figsize=(12,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
    "        plt.plot(history[\"val_loss\"], label=\"Val Loss\")\n",
    "        plt.title(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot([x*100 for x in history[\"train_acc\"]], label=\"Train Acc\")\n",
    "        plt.plot([x*100 for x in history[\"val_acc\"]], label=\"Val Acc\")\n",
    "        plt.title(\"Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = 8  \n",
    "model = ResNet50Finetuner(num_classes=num_classes, freeze_backbone=True)\n",
    "model.explore(input_size=(1, 3, 224, 224))\n",
    "\n",
    "# Test forward pass\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "out = model(dummy_input)\n",
    "print(\"\\nForward pass output shape:\", out.shape)  # should be [1, num_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_classes = 8\n",
    "model = ResNet50Finetuner(num_classes=num_classes, freeze_backbone=True, lr=1e-3, use_scheduler=True)\n",
    "\n",
    "model.explore(input_size=(1,3,224,224))\n",
    "\n",
    "history = model.train_model(train_loader, val_loader, epochs=3)\n",
    "\n",
    "model.plot_history(history)\n",
    "\n",
    "sample_image, _ = val_dataset[0]  \n",
    "pred_class = model.predict(sample_image)\n",
    "print(f\"Predicted class: {pred_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "num_classes = 8\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = models.resnet50(weights=None)\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "model.load_state_dict(torch.load(r\"../../bbest_resnet50.pth\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "def predict_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0)  # إضافة بعد الـ batch\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model(image)\n",
    "        predicted_class = outputs.argmax(dim=1).item()\n",
    "    return predicted_class\n",
    "\n",
    "# {'l-pass': 0, 'l-spike': 1, 'l_set': 2, 'l_winpoint': 3, 'r-pass': 4, 'r_set': 5, 'r_spike': 6, 'r_winpoint': 7}\n",
    "# data/volleyball/volleyball_/videos/0/13286/13281.jpg ==> r_set\n",
    "# 'path': 'data/volleyball/volleyball_/videos/31/31295/31295.jpg', r_spike\n",
    "\n",
    "\n",
    "image_path = r\"../../data/volleyball/volleyball_/videos/0/13286/13273.jpg\"\n",
    "# image_path = r\"../../data/volleyball/volleyball_/videos/31/31295/31295.jpg\"\n",
    "\n",
    "pred_class = predict_image(image_path)\n",
    "print(f\"Predicted class: {pred_class}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
