{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# Add project root so that `src` package is discoverable\n",
    "project_root = os.path.abspath(os.path.join(\"..\", \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pickle\n",
    "\n",
    "# def load_pkl():\n",
    "#     # Get project root (2 levels up from notebook folder)\n",
    "#     project_root = os.path.abspath(os.path.join(\"..\", \"..\"))\n",
    "#     file_path = os.path.join(project_root, \"datapkl\", \"annot_all.pkl\")\n",
    "\n",
    "#     with open(file_path, \"rb\") as file:\n",
    "#         videos_annot = pickle.load(file)\n",
    "#     return videos_annot, file_path\n",
    "\n",
    "# videos_annot_dct, file_path = load_pkl()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from src.enums.PathEnums import Paths\n",
    "# data_annot = []\n",
    "# labels = set()\n",
    "\n",
    "\n",
    "# for video_id, clips in videos_annot_dct.items():  # each video\n",
    "    \n",
    "#     for clip_id, clip_data in clips.items():  # each clip\n",
    "#         category = clip_data['category']\n",
    "#         labels.add(category)\n",
    "        \n",
    "#         for frame_id, boxes in clip_data[\"frame_boxes_dct\"].items(): # Frames\n",
    "\n",
    "#             frame_path = f\"{Paths.VIDEOS_ROOT.value}/{video_id}/{clip_id}/{frame_id}.jpg\"\n",
    "#             data_annot.append(\n",
    "#                 {\n",
    "#                 \"path\": frame_path,\n",
    "#                 \"category\" :category\n",
    "#                 }\n",
    "#             )\n",
    "\n",
    "# print(f\"{len(labels)} labels: {labels}\\n\\n\")\n",
    "\n",
    "# categories_dct = {\n",
    "#         'l-pass': 0,\n",
    "#         'r-pass': 1,\n",
    "#         'l-spike': 2,\n",
    "#         'r_spike': 3,\n",
    "#         'l_set': 4,\n",
    "#         'r_set': 5,\n",
    "#         'l_winpoint': 6,\n",
    "#         'r_winpoint': 7\n",
    "#     }\n",
    "\n",
    "\n",
    "# len_dataset = len(data_annot)\n",
    "# len_dataset, int(len_dataset*0.6), int(len_dataset*0.3), int(len_dataset*0.1)\n",
    "\n",
    "# from pathlib import Path\n",
    "\n",
    "\n",
    "# # Group-Activity-Recognition/data\n",
    "\n",
    "\n",
    "# FRAMES_PATH = Path(\"../../FramesData/\")\n",
    "# TRAIN_PATH =  FRAMES_PATH / \"train\"\n",
    "# VALID_PATH = FRAMES_PATH / \"valid\"\n",
    "# TEST_PATH = FRAMES_PATH / \"test\"\n",
    "# print(TRAIN_PATH, VALID_PATH, TEST_PATH)\n",
    "\n",
    "# if FRAMES_PATH.is_dir():\n",
    "#     print(f\"{FRAMES_PATH} directory exists.\")\n",
    "\n",
    "\n",
    "# FRAMES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "# TRAIN_PATH.mkdir(parents=True, exist_ok=True)\n",
    "# VALID_PATH.mkdir(parents=True, exist_ok=True)\n",
    "# TEST_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "def load_pkl():\n",
    "    # Get project root (2 levels up from notebook folder)\n",
    "    project_root = os.path.abspath(os.path.join(\"..\", \"..\"))\n",
    "    file_path = os.path.join(project_root, \"datapkl\", \"annot_all.pkl\")\n",
    "\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        videos_annot = pickle.load(file)\n",
    "    return videos_annot, file_path\n",
    "\n",
    "videos_annot_dct, file_path = load_pkl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "print(len(videos_annot_dct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 labels: {'r_set', 'l-spike', 'r_winpoint', 'l-pass', 'l_winpoint', 'l_set', 'r-pass', 'r_spike'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.enums.PathEnums import Paths\n",
    "data_annot = []\n",
    "labels = set()\n",
    "\n",
    "\n",
    "for video_id, clips in videos_annot_dct.items():  # each video\n",
    "    \n",
    "    for clip_id, clip_data in clips.items():  # each clip\n",
    "        category = clip_data['category']\n",
    "        labels.add(category)\n",
    "        \n",
    "        for frame_id, boxes in clip_data[\"frame_boxes_dct\"].items(): # Frames\n",
    "\n",
    "            frame_path = f\"{Paths.VIDEOS_ROOT.value}/{video_id}/{clip_id}/{frame_id}.jpg\"\n",
    "            data_annot.append(\n",
    "                {\n",
    "                \"path\": frame_path,\n",
    "                \"category\" :category\n",
    "                }\n",
    "            )\n",
    "\n",
    "print(f\"{len(labels)} labels: {labels}\\n\\n\")\n",
    "\n",
    "categories_dct = {\n",
    "        'l-pass': 0,\n",
    "        'r-pass': 1,\n",
    "        'l-spike': 2,\n",
    "        'r_spike': 3,\n",
    "        'l_set': 4,\n",
    "        'r_set': 5,\n",
    "        'l_winpoint': 6,\n",
    "        'r_winpoint': 7\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/volleyball/volleyball_/videos/0/13286/13281.jpg ==> r_set\n"
     ]
    }
   ],
   "source": [
    "for frame_dct in data_annot:\n",
    "    for path, cat in frame_dct.items():\n",
    "        print(frame_dct[\"path\"], \"==>\", frame_dct[\"category\"])\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43470, 26082, 13041, 4347)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_dataset = len(data_annot)\n",
    "len_dataset, int(len_dataset*0.6), int(len_dataset*0.3), int(len_dataset*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43470"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len_dataset*0.6) +  int(len_dataset*0.3) + int(len_dataset*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../FramesData/train ../../FramesData/valid ../../FramesData/test\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Group-Activity-Recognition/data\n",
    "\n",
    "\n",
    "FRAMES_PATH = Path(\"../../FramesData/\")\n",
    "TRAIN_PATH =  FRAMES_PATH / \"train\"\n",
    "VALID_PATH = FRAMES_PATH / \"valid\"\n",
    "TEST_PATH = FRAMES_PATH / \"test\"\n",
    "print(TRAIN_PATH, VALID_PATH, TEST_PATH)\n",
    "\n",
    "if FRAMES_PATH.is_dir():\n",
    "    print(f\"{FRAMES_PATH} directory exists.\")\n",
    "\n",
    "\n",
    "FRAMES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "TRAIN_PATH.mkdir(parents=True, exist_ok=True)\n",
    "VALID_PATH.mkdir(parents=True, exist_ok=True)\n",
    "TEST_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(data_annot)  # shuffle before splitting\n",
    "\n",
    "n_total = len(data_annot)\n",
    "n_train = int(0.6 * n_total)\n",
    "n_valid = int(0.3 * n_total)\n",
    "n_test = n_total - n_train - n_valid\n",
    "\n",
    "train_data = data_annot[:n_train]\n",
    "valid_data = data_annot[n_train:n_train+n_valid]\n",
    "test_data  = data_annot[n_train+n_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26082 26082\n",
      "13041 13041\n",
      "4347 4347\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), n_train)\n",
    "print(len(valid_data), n_valid)\n",
    "print(len(test_data), n_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/volleyball/volleyball_/videos/42/37915/37915.jpg\n",
      "l-pass\n"
     ]
    }
   ],
   "source": [
    "for item in train_data:\n",
    "    print(item[\"path\"])\n",
    "    print(item[\"category\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 37915.jpg\n"
     ]
    }
   ],
   "source": [
    "path = Path(r'../../data/volleyball/volleyball_/videos/42/37915/37915.jpg')\n",
    "vid_num = path.parents[1].name\n",
    "s = os.path.basename(path)\n",
    "print(vid_num, s)\n",
    "# os.path.exists(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def save_split(data_split, split_path):\n",
    "\n",
    "    for item in data_split:\n",
    "\n",
    "        src = os.path.join(\"../../\", Path(item[\"path\"]))\n",
    "        label = item[\"category\"]\n",
    "        dst_dir = split_path / label\n",
    "        dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        print(src, \"\\n\", label, dst_dir)\n",
    "\n",
    "        # vid_num = src.parents[1].name\n",
    "        # print(vid_num)\n",
    "        # dst = dst_dir / f\"vid_{vid_num}_{os.path.basename(src)}\"\n",
    "        # # dst = dst_dir / f\"{vid_num}_{os.path.basename(src)}\"\n",
    "\n",
    "        # print(src)\n",
    "        # print(dst)\n",
    "        break\n",
    "save_split(train_data, TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/volleyball/volleyball_/videos/42/37915/37915.jpg \n",
      " l-pass ../../FramesData/train/l-pass\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "def save_split(data_split, split_path):\n",
    "\n",
    "    for item in data_split:\n",
    "\n",
    "        src = os.path.join(\"../../\", Path(item[\"path\"]))\n",
    "        label = item[\"category\"]\n",
    "        dst_dir = split_path / label\n",
    "        dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        print(src, \"\\n\", label, dst_dir)\n",
    "\n",
    "        # vid_num = src.parents[1].name\n",
    "        # print(vid_num)\n",
    "        # dst = dst_dir / f\"vid_{vid_num}_{os.path.basename(src)}\"\n",
    "        # # dst = dst_dir / f\"{vid_num}_{os.path.basename(src)}\"\n",
    "\n",
    "        # print(src)\n",
    "        # print(dst)\n",
    "        break\n",
    "\n",
    "        # try:\n",
    "        #     if not os.path.exists(src):\n",
    "\n",
    "        #     if dst.exists():\n",
    "        #         print(f\"Overwriting: {dst}\")  # check duplicates\n",
    "\n",
    "        #     shutil.copy(src, dst)\n",
    "\n",
    "        # except Exception as e:\n",
    "        #     print(f\"Error copying {src} → {dst}: {e}\")\n",
    "\n",
    "\n",
    "save_split(train_data, TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
