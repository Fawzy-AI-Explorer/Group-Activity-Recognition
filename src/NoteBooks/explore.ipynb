{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# Add project root so that `src` package is discoverable\n",
    "project_root = os.path.abspath(os.path.join(\"..\", \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pickle\n",
    "\n",
    "# def load_pkl():\n",
    "#     # Get project root (2 levels up from notebook folder)\n",
    "#     project_root = os.path.abspath(os.path.join(\"..\", \"..\"))\n",
    "#     file_path = os.path.join(project_root, \"datapkl\", \"annot_all.pkl\")\n",
    "\n",
    "#     with open(file_path, \"rb\") as file:\n",
    "#         videos_annot = pickle.load(file)\n",
    "#     return videos_annot, file_path\n",
    "\n",
    "# videos_annot_dct, file_path = load_pkl()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from src.enums.PathEnums import Paths\n",
    "# data_annot = []\n",
    "# labels = set()\n",
    "\n",
    "\n",
    "# for video_id, clips in videos_annot_dct.items():  # each video\n",
    "    \n",
    "#     for clip_id, clip_data in clips.items():  # each clip\n",
    "#         category = clip_data['category']\n",
    "#         labels.add(category)\n",
    "        \n",
    "#         for frame_id, boxes in clip_data[\"frame_boxes_dct\"].items(): # Frames\n",
    "\n",
    "#             frame_path = f\"{Paths.VIDEOS_ROOT.value}/{video_id}/{clip_id}/{frame_id}.jpg\"\n",
    "#             data_annot.append(\n",
    "#                 {\n",
    "#                 \"path\": frame_path,\n",
    "#                 \"category\" :category\n",
    "#                 }\n",
    "#             )\n",
    "\n",
    "# print(f\"{len(labels)} labels: {labels}\\n\\n\")\n",
    "\n",
    "# categories_dct = {\n",
    "#         'l-pass': 0,\n",
    "#         'r-pass': 1,\n",
    "#         'l-spike': 2,\n",
    "#         'r_spike': 3,\n",
    "#         'l_set': 4,\n",
    "#         'r_set': 5,\n",
    "#         'l_winpoint': 6,\n",
    "#         'r_winpoint': 7\n",
    "#     }\n",
    "\n",
    "\n",
    "# len_dataset = len(data_annot)\n",
    "# len_dataset, int(len_dataset*0.6), int(len_dataset*0.3), int(len_dataset*0.1)\n",
    "\n",
    "# from pathlib import Path\n",
    "\n",
    "\n",
    "# # Group-Activity-Recognition/data\n",
    "\n",
    "\n",
    "# FRAMES_PATH = Path(\"../../FramesData/\")\n",
    "# TRAIN_PATH =  FRAMES_PATH / \"train\"\n",
    "# VALID_PATH = FRAMES_PATH / \"valid\"\n",
    "# TEST_PATH = FRAMES_PATH / \"test\"\n",
    "# print(TRAIN_PATH, VALID_PATH, TEST_PATH)\n",
    "\n",
    "# if FRAMES_PATH.is_dir():\n",
    "#     print(f\"{FRAMES_PATH} directory exists.\")\n",
    "\n",
    "\n",
    "# FRAMES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "# TRAIN_PATH.mkdir(parents=True, exist_ok=True)\n",
    "# VALID_PATH.mkdir(parents=True, exist_ok=True)\n",
    "# TEST_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "def load_pkl():\n",
    "    # Get project root (2 levels up from notebook folder)\n",
    "    project_root = os.path.abspath(os.path.join(\"..\", \"..\"))\n",
    "    file_path = os.path.join(project_root, \"datapkl\", \"annot_all.pkl\")\n",
    "\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        videos_annot = pickle.load(file)\n",
    "    return videos_annot, file_path\n",
    "\n",
    "videos_annot_dct, file_path = load_pkl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "print(len(videos_annot_dct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 labels: {'l-spike', 'l_winpoint', 'r_set', 'r_winpoint', 'l_set', 'l-pass', 'r_spike', 'r-pass'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.enums.PathEnums import Paths\n",
    "data_annot = []\n",
    "labels = set()\n",
    "\n",
    "\n",
    "for video_id, clips in videos_annot_dct.items():  # each video\n",
    "    \n",
    "    for clip_id, clip_data in clips.items():  # each clip\n",
    "        category = clip_data['category']\n",
    "        labels.add(category)\n",
    "        \n",
    "        for frame_id, boxes in clip_data[\"frame_boxes_dct\"].items(): # Frames\n",
    "\n",
    "            frame_path = f\"{Paths.VIDEOS_ROOT.value}/{video_id}/{clip_id}/{frame_id}.jpg\"\n",
    "            data_annot.append(\n",
    "                {\n",
    "                \"path\": frame_path,\n",
    "                \"category\" :category\n",
    "                }\n",
    "            )\n",
    "\n",
    "print(f\"{len(labels)} labels: {labels}\\n\\n\")\n",
    "\n",
    "categories_dct = {\n",
    "        'l-pass': 0,\n",
    "        'r-pass': 1,\n",
    "        'l-spike': 2,\n",
    "        'r_spike': 3,\n",
    "        'l_set': 4,\n",
    "        'r_set': 5,\n",
    "        'l_winpoint': 6,\n",
    "        'r_winpoint': 7\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/volleyball/volleyball_/videos/0/13286/13281.jpg ==> r_set\n"
     ]
    }
   ],
   "source": [
    "for frame_dct in data_annot:\n",
    "    for path, cat in frame_dct.items():\n",
    "        print(frame_dct[\"path\"], \"==>\", frame_dct[\"category\"])\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43470, 26082, 13041, 4347)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_dataset = len(data_annot)\n",
    "len_dataset, int(len_dataset*0.6), int(len_dataset*0.3), int(len_dataset*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43470"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len_dataset*0.6) +  int(len_dataset*0.3) + int(len_dataset*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../FramesData/train ../../FramesData/valid ../../FramesData/test\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Group-Activity-Recognition/data\n",
    "\n",
    "\n",
    "FRAMES_PATH = Path(\"../../FramesData/\")\n",
    "TRAIN_PATH =  FRAMES_PATH / \"train\"\n",
    "VALID_PATH = FRAMES_PATH / \"valid\"\n",
    "TEST_PATH = FRAMES_PATH / \"test\"\n",
    "print(TRAIN_PATH, VALID_PATH, TEST_PATH)\n",
    "\n",
    "if FRAMES_PATH.is_dir():\n",
    "    print(f\"{FRAMES_PATH} directory exists.\")\n",
    "\n",
    "\n",
    "FRAMES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "TRAIN_PATH.mkdir(parents=True, exist_ok=True)\n",
    "VALID_PATH.mkdir(parents=True, exist_ok=True)\n",
    "TEST_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(data_annot)  # shuffle before splitting\n",
    "\n",
    "n_total = len(data_annot)\n",
    "n_train = int(0.6 * n_total)\n",
    "n_valid = int(0.3 * n_total)\n",
    "n_test = n_total - n_train - n_valid\n",
    "\n",
    "train_data = data_annot[:n_train]\n",
    "valid_data = data_annot[n_train:n_train+n_valid]\n",
    "test_data  = data_annot[n_train+n_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26082 26082\n",
      "13041 13041\n",
      "4347 4347\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), n_train)\n",
    "print(len(valid_data), n_valid)\n",
    "print(len(test_data), n_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/volleyball/volleyball_/videos/14/54185/54182.jpg\n",
      "l-spike\n"
     ]
    }
   ],
   "source": [
    "for item in train_data:\n",
    "    print(item[\"path\"])\n",
    "    print(item[\"category\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 37915.jpg\n"
     ]
    }
   ],
   "source": [
    "path = Path(r'../../data/volleyball/volleyball_/videos/42/37915/37915.jpg')\n",
    "vid_num = path.parents[1].name\n",
    "s = os.path.basename(path)\n",
    "print(vid_num, s)\n",
    "# os.path.exists(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 26082\n",
      "start, ../../FramesData/train \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25963\n",
      "valid 13041\n",
      "start, ../../FramesData/valid \n",
      "13002\n",
      "test 4347\n",
      "start, ../../FramesData/test \n",
      "4344\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "def save_split(data_split, split_path):\n",
    "    print(f\"start, {split_path} \")\n",
    "    i=0\n",
    "\n",
    "    for item in data_split:\n",
    "\n",
    "        src = os.path.join(\"../../\", Path(item[\"path\"]))\n",
    "        label = item[\"category\"]\n",
    "        dst_dir = split_path / label\n",
    "        dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # print(src, os.path.exists(src))\n",
    "        # print(label)\n",
    "        # print(dst_dir)\n",
    "\n",
    "\n",
    "        vid_num = Path(src).parents[1].name\n",
    "        dst = dst_dir / f\"vid_{vid_num}_{os.path.basename(src)}\"\n",
    "        dst = dst_dir / f\"vid_{vid_num}_{os.path.basename(src)}\"\n",
    "\n",
    "        # print(vid_num)\n",
    "        # print(dst)\n",
    "\n",
    "\n",
    "        try:\n",
    "            if os.path.exists(dst):\n",
    "                # print(\"override\", dst)\n",
    "                i-=1\n",
    "            shutil.copy(src, dst)\n",
    "            i+=1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error copying {src} → {dst}: {e}\")\n",
    "\n",
    "    print(i)\n",
    "\n",
    "print(f\"train {n_train}\")\n",
    "save_split(train_data, TRAIN_PATH)\n",
    "\n",
    "print(f\"valid {n_valid}\")\n",
    "save_split(valid_data, VALID_PATH)\n",
    "\n",
    "print(f\"test {n_test}\")\n",
    "save_split(test_data, TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r_winpoint',\n",
       " 'l_winpoint',\n",
       " 'l-spike',\n",
       " 'l_set',\n",
       " 'l-pass',\n",
       " 'r_spike',\n",
       " 'r-pass',\n",
       " 'r_set']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_list_of_directories(dir_path):\n",
    "    \"\"\"Returns a list of directory names (not full paths) in dir_path.\"\"\"\n",
    "    return [\n",
    "        directory for directory in os.listdir(dir_path)\n",
    "        if os.path.isdir(os.path.join(dir_path, directory))\n",
    "    ]\n",
    "\n",
    "get_list_of_directories(TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 directories, ['train', 'test', 'valid']\n",
      "There are 8 directories, ['r_winpoint', 'l_winpoint', 'l-spike', 'l_set', 'l-pass', 'r_spike', 'r-pass', 'r_set']\n",
      "    There are 1605 images in '../../FramesData/train/r_winpoint'.\n",
      "    There are 1983 images in '../../FramesData/train/l_winpoint'.\n",
      "    There are 3392 images in '../../FramesData/train/l-spike'.\n",
      "    There are 3353 images in '../../FramesData/train/l_set'.\n",
      "    There are 4474 images in '../../FramesData/train/l-pass'.\n",
      "    There are 3306 images in '../../FramesData/train/r_spike'.\n",
      "    There are 4366 images in '../../FramesData/train/r-pass'.\n",
      "    There are 3484 images in '../../FramesData/train/r_set'.\n",
      "There are 8 directories, ['r_winpoint', 'l_winpoint', 'l-spike', 'l_set', 'l-pass', 'r_spike', 'r-pass', 'r_set']\n",
      "    There are 272 images in '../../FramesData/test/r_winpoint'.\n",
      "    There are 338 images in '../../FramesData/test/l_winpoint'.\n",
      "    There are 558 images in '../../FramesData/test/l-spike'.\n",
      "    There are 573 images in '../../FramesData/test/l_set'.\n",
      "    There are 716 images in '../../FramesData/test/l-pass'.\n",
      "    There are 576 images in '../../FramesData/test/r_spike'.\n",
      "    There are 712 images in '../../FramesData/test/r-pass'.\n",
      "    There are 599 images in '../../FramesData/test/r_set'.\n",
      "There are 8 directories, ['r_winpoint', 'l_winpoint', 'l-spike', 'l_set', 'l-pass', 'r_spike', 'r-pass', 'r_set']\n",
      "    There are 778 images in '../../FramesData/valid/r_winpoint'.\n",
      "    There are 982 images in '../../FramesData/valid/l_winpoint'.\n",
      "    There are 1763 images in '../../FramesData/valid/l-spike'.\n",
      "    There are 1756 images in '../../FramesData/valid/l_set'.\n",
      "    There are 2235 images in '../../FramesData/valid/l-pass'.\n",
      "    There are 1660 images in '../../FramesData/valid/r_spike'.\n",
      "    There are 2120 images in '../../FramesData/valid/r-pass'.\n",
      "    There are 1708 images in '../../FramesData/valid/r_set'.\n"
     ]
    }
   ],
   "source": [
    "def walk_through_dir(dir_path):\n",
    "  \"\"\" Walks through dir_path returning its contents. \"\"\"\n",
    "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "    if len(dirnames) > 0:\n",
    "        dirs = get_list_of_directories(dirpath)\n",
    "        print(f\"There are {len(dirnames)} directories, {dirs}\")\n",
    "    if len(filenames) > 0:\n",
    "        print(f\"    There are {len(filenames)} images in '{dirpath}'.\")\n",
    "\n",
    "# data_path = Path(\"data/\")\n",
    "# image_path = data_path / \"pizza_steak_sushi\"\n",
    "walk_through_dir(FRAMES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
